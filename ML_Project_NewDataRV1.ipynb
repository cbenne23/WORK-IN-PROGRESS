{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ChrisB\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th>  <td>   0.703</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th>  <td>   0.703</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>  <td>   2560.</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Wed, 11 Oct 2017</td> <th>  Prob (F-statistic):</th>   <td>  0.00</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>21:52:21</td>     <th>  Log-Likelihood:    </th> <td>-2.9449e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td> 21613</td>      <th>  AIC:               </th>  <td>5.890e+05</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td> 21592</td>      <th>  BIC:               </th>  <td>5.892e+05</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    20</td>      <th>                     </th>      <td> </td>     \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>      <td> </td>     \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>-9.484e+06</td> <td> 2.47e+06</td> <td>   -3.832</td> <td> 0.000</td> <td>-1.43e+07</td> <td>-4.63e+06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td> 1.013e+05</td> <td> 1.12e+04</td> <td>    9.004</td> <td> 0.000</td> <td> 7.92e+04</td> <td> 1.23e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td> 6.279e+04</td> <td> 6827.819</td> <td>    9.197</td> <td> 0.000</td> <td> 4.94e+04</td> <td> 7.62e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td> 1.298e+05</td> <td> 9377.613</td> <td>   13.843</td> <td> 0.000</td> <td> 1.11e+05</td> <td> 1.48e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th>    <td> 2.869e+05</td> <td> 1.44e+04</td> <td>   19.965</td> <td> 0.000</td> <td> 2.59e+05</td> <td> 3.15e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5</th>    <td> 5.082e+05</td> <td> 1.96e+04</td> <td>   25.921</td> <td> 0.000</td> <td>  4.7e+05</td> <td> 5.47e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x6</th>    <td>  3.44e+04</td> <td> 7259.808</td> <td>    4.738</td> <td> 0.000</td> <td> 2.02e+04</td> <td> 4.86e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x7</th>    <td>-1.703e+06</td> <td> 6.71e+05</td> <td>   -2.536</td> <td> 0.011</td> <td>-3.02e+06</td> <td>-3.87e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x8</th>    <td>-1.332e+07</td> <td> 7.96e+05</td> <td>  -16.728</td> <td> 0.000</td> <td>-1.49e+07</td> <td>-1.18e+07</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x9</th>    <td>  106.7960</td> <td>    2.266</td> <td>   47.131</td> <td> 0.000</td> <td>  102.355</td> <td>  111.237</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x10</th>   <td>   -0.0396</td> <td>    0.035</td> <td>   -1.145</td> <td> 0.252</td> <td>   -0.107</td> <td>    0.028</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x11</th>   <td> 4732.6146</td> <td> 3563.852</td> <td>    1.328</td> <td> 0.184</td> <td>-2252.798</td> <td> 1.17e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x12</th>   <td>   2.7e+04</td> <td> 2329.043</td> <td>   11.591</td> <td> 0.000</td> <td> 2.24e+04</td> <td> 3.16e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x13</th>   <td> 9.706e+04</td> <td> 2141.909</td> <td>   45.313</td> <td> 0.000</td> <td> 9.29e+04</td> <td> 1.01e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x14</th>   <td>   69.5295</td> <td>    2.244</td> <td>   30.985</td> <td> 0.000</td> <td>   65.131</td> <td>   73.928</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x15</th>   <td>   37.2664</td> <td>    2.635</td> <td>   14.144</td> <td> 0.000</td> <td>   32.102</td> <td>   42.431</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x16</th>   <td> 2518.8038</td> <td>   71.785</td> <td>   35.088</td> <td> 0.000</td> <td> 2378.100</td> <td> 2659.508</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x17</th>   <td>-1.403e+05</td> <td> 4.35e+04</td> <td>   -3.224</td> <td> 0.001</td> <td>-2.26e+05</td> <td> -5.5e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x18</th>   <td> 2.808e+05</td> <td> 1.67e+04</td> <td>   16.783</td> <td> 0.000</td> <td> 2.48e+05</td> <td> 3.14e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x19</th>   <td> 3.502e+04</td> <td> 1.41e+04</td> <td>    2.482</td> <td> 0.013</td> <td> 7363.234</td> <td> 6.27e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x20</th>   <td>-1.256e+05</td> <td> 1.18e+04</td> <td>  -10.614</td> <td> 0.000</td> <td>-1.49e+05</td> <td>-1.02e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x21</th>   <td>   30.9533</td> <td>    3.424</td> <td>    9.040</td> <td> 0.000</td> <td>   24.242</td> <td>   37.665</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>18178.626</td> <th>  Durbin-Watson:     </th>  <td>   1.992</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>  <td> 0.000</td>   <th>  Jarque-Bera (JB):  </th> <td>1812393.471</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>           <td> 3.505</td>   <th>  Prob(JB):          </th>  <td>    0.00</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>       <td>47.310</td>   <th>  Cond. No.          </th>  <td>1.04e+17</td>  \n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.703\n",
       "Model:                            OLS   Adj. R-squared:                  0.703\n",
       "Method:                 Least Squares   F-statistic:                     2560.\n",
       "Date:                Wed, 11 Oct 2017   Prob (F-statistic):               0.00\n",
       "Time:                        21:52:21   Log-Likelihood:            -2.9449e+05\n",
       "No. Observations:               21613   AIC:                         5.890e+05\n",
       "Df Residuals:                   21592   BIC:                         5.892e+05\n",
       "Df Model:                          20                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const      -9.484e+06   2.47e+06     -3.832      0.000   -1.43e+07   -4.63e+06\n",
       "x1          1.013e+05   1.12e+04      9.004      0.000    7.92e+04    1.23e+05\n",
       "x2          6.279e+04   6827.819      9.197      0.000    4.94e+04    7.62e+04\n",
       "x3          1.298e+05   9377.613     13.843      0.000    1.11e+05    1.48e+05\n",
       "x4          2.869e+05   1.44e+04     19.965      0.000    2.59e+05    3.15e+05\n",
       "x5          5.082e+05   1.96e+04     25.921      0.000     4.7e+05    5.47e+05\n",
       "x6           3.44e+04   7259.808      4.738      0.000    2.02e+04    4.86e+04\n",
       "x7         -1.703e+06   6.71e+05     -2.536      0.011   -3.02e+06   -3.87e+05\n",
       "x8         -1.332e+07   7.96e+05    -16.728      0.000   -1.49e+07   -1.18e+07\n",
       "x9           106.7960      2.266     47.131      0.000     102.355     111.237\n",
       "x10           -0.0396      0.035     -1.145      0.252      -0.107       0.028\n",
       "x11         4732.6146   3563.852      1.328      0.184   -2252.798    1.17e+04\n",
       "x12           2.7e+04   2329.043     11.591      0.000    2.24e+04    3.16e+04\n",
       "x13         9.706e+04   2141.909     45.313      0.000    9.29e+04    1.01e+05\n",
       "x14           69.5295      2.244     30.985      0.000      65.131      73.928\n",
       "x15           37.2664      2.635     14.144      0.000      32.102      42.431\n",
       "x16         2518.8038     71.785     35.088      0.000    2378.100    2659.508\n",
       "x17        -1.403e+05   4.35e+04     -3.224      0.001   -2.26e+05    -5.5e+04\n",
       "x18         2.808e+05   1.67e+04     16.783      0.000    2.48e+05    3.14e+05\n",
       "x19         3.502e+04   1.41e+04      2.482      0.013    7363.234    6.27e+04\n",
       "x20        -1.256e+05   1.18e+04    -10.614      0.000   -1.49e+05   -1.02e+05\n",
       "x21           30.9533      3.424      9.040      0.000      24.242      37.665\n",
       "==============================================================================\n",
       "Omnibus:                    18178.626   Durbin-Watson:                   1.992\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):          1812393.471\n",
       "Skew:                           3.505   Prob(JB):                         0.00\n",
       "Kurtosis:                      47.310   Cond. No.                     1.04e+17\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The smallest eigenvalue is 3.91e-21. This might indicate that there are\n",
       "strong multicollinearity problems or that the design matrix is singular.\n",
       "\"\"\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Multiple Linear Regression\n",
    "\n",
    "# Importing the libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Importing the dataset\n",
    "\n",
    "dataset = pd.read_csv('C:\\\\Users\\\\ChrisB\\\\Documents\\\\PRINCIPALANALYTICSPREP\\\\ML\\\\HOMEWORK_1\\\\DATASET\\\\House_data1.csv', delimiter =',')\n",
    "#dataset = pd.read_csv('House_data1.csv')\n",
    "Res = [0,1,2,3,4,5,8,9,10,11,12,14,15,16,17,18]\n",
    "dataset1=dataset.iloc[:,Res].values\n",
    "\n",
    "X = dataset1[:, 1:]\n",
    "y = dataset1[:, 0]\n",
    "\n",
    "V = dataset.iloc[:, 7:8].values\n",
    "W = dataset.iloc[:, 6:7].values\n",
    "R = dataset.iloc[:, 13:14].values\n",
    "\n",
    "# Encoding categorical data\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "# Encoding the \"View\"variable\n",
    "#labelencoder = LabelEncoder()\n",
    "#X[:, 3] = labelencoder.fit_transform(X[:, 3])\n",
    "onehotencoder = OneHotEncoder(categorical_features = [0])\n",
    "V1 = onehotencoder.fit_transform(V).toarray()\n",
    "\n",
    "# Encoding categorical data\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "# Encoding the \"WaterFront\"variable\n",
    "#labelencoder = LabelEncoder()\n",
    "#X[:, 3] = labelencoder.fit_transform(X[:, 3])\n",
    "onehotencoder = OneHotEncoder(categorical_features = [0])\n",
    "W1 = onehotencoder.fit_transform(W).toarray()\n",
    "\n",
    "\n",
    "# Encoding categorical data\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "# Encoding the \"Renovated\"variable\n",
    "#labelencoder = LabelEncoder()\n",
    "#X[:, 3] = labelencoder.fit_transform(X[:, 3])\n",
    "onehotencoder = OneHotEncoder(categorical_features = [0])\n",
    "R1 = onehotencoder.fit_transform(R).toarray()\n",
    "\n",
    "# Avoiding the Dummy Variable Trap\n",
    "V1 = V1[:, 1:]\n",
    "\n",
    "# Avoiding the Dummy Variable Trap\n",
    "W1 = W1[:, 1:2]\n",
    "\n",
    "# Avoiding the Dummy Variable Trap\n",
    "R1 = R1[:, 1:2]\n",
    "\n",
    "#Merging DataFrames\n",
    "\n",
    "# place the DataFrames side by side\n",
    "#newdata = np.concatenate((V1,W1,R1,X), axis=1)\n",
    "\n",
    "X=pd.DataFrame(X)\n",
    "V1=pd.DataFrame(V1)\n",
    "W1=pd.DataFrame(W1)\n",
    "R1=pd.DataFrame(R1)\n",
    "\n",
    "newdata = pd.concat([V1,W1,R1,X], axis=1)\n",
    "\n",
    "x=newdata.iloc[:,0:].values\n",
    "\n",
    "\n",
    "# Splitting the dataset into the Training set and Test set\n",
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 0)\n",
    "\n",
    "# Feature Scaling\n",
    "\"\"\"from sklearn.preprocessing import StandardScaler\n",
    "sc_X = StandardScaler()\n",
    "X_train = sc_X.fit_transform(X_train)\n",
    "X_test = sc_X.transform(X_test)\n",
    "sc_y = StandardScaler()\n",
    "y_train = sc_y.fit_transform(y_train)\"\"\"\n",
    "\n",
    "# Fitting Multiple Linear Regression to the Training set\n",
    "\"\"\"from sklearn.linear_model import LinearRegression\n",
    "regressor = LinearRegression()\n",
    "regressor.fit(X_train, y_train)\n",
    "\n",
    "# Predicting the Test set results\n",
    "y_pred = regressor.predict(X_test)\n",
    "\n",
    "# Evaluating Model Performance\n",
    "from sklearn.metrics import mean_squared_error\n",
    "lin_mse_LR = mean_squared_error(y_test, y_pred)\n",
    "lin_rmse_LR = np.sqrt(lin_mse)\n",
    "lin_rmse_LR\"\"\"\n",
    "\n",
    "#Building the optimal model using Backward Elimination -Kitchen Sink Model\n",
    "import statsmodels.formula.api as sm\n",
    "x=np.append(arr=np.ones((21613,1)).astype(int), values =x, axis=1)\n",
    "x_opt =x[:,[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21]]\n",
    "regressor_OLS =sm.OLS(endog =y, exog=x_opt).fit()\n",
    "regressor_OLS.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th>  <td>   0.702</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th>  <td>   0.702</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>  <td>   2680.</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Wed, 11 Oct 2017</td> <th>  Prob (F-statistic):</th>   <td>  0.00</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>21:57:52</td>     <th>  Log-Likelihood:    </th> <td>-2.9453e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td> 21613</td>      <th>  AIC:               </th>  <td>5.891e+05</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td> 21593</td>      <th>  BIC:               </th>  <td>5.893e+05</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    19</td>      <th>                     </th>      <td> </td>     \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>      <td> </td>     \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>-3.705e+06</td> <td> 1.23e+06</td> <td>   -3.002</td> <td> 0.003</td> <td>-6.12e+06</td> <td>-1.29e+06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>-3.705e+06</td> <td> 1.23e+06</td> <td>   -3.002</td> <td> 0.003</td> <td>-6.12e+06</td> <td>-1.29e+06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td> 1.096e+05</td> <td> 1.12e+04</td> <td>    9.763</td> <td> 0.000</td> <td> 8.76e+04</td> <td> 1.32e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td> 6.868e+04</td> <td> 6809.365</td> <td>   10.086</td> <td> 0.000</td> <td> 5.53e+04</td> <td>  8.2e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th>    <td> 1.388e+05</td> <td> 9342.321</td> <td>   14.856</td> <td> 0.000</td> <td>  1.2e+05</td> <td> 1.57e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5</th>    <td> 2.963e+05</td> <td> 1.44e+04</td> <td>   20.639</td> <td> 0.000</td> <td> 2.68e+05</td> <td> 3.24e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x6</th>    <td>  5.06e+05</td> <td> 1.96e+04</td> <td>   25.760</td> <td> 0.000</td> <td> 4.67e+05</td> <td> 5.44e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x7</th>    <td> 3.122e+04</td> <td> 7264.811</td> <td>    4.297</td> <td> 0.000</td> <td>  1.7e+04</td> <td> 4.55e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x8</th>    <td>  -1.8e+06</td> <td> 6.72e+05</td> <td>   -2.677</td> <td> 0.007</td> <td>-3.12e+06</td> <td>-4.82e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x9</th>    <td>-1.283e+07</td> <td> 7.96e+05</td> <td>  -16.124</td> <td> 0.000</td> <td>-1.44e+07</td> <td>-1.13e+07</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x10</th>   <td>   -0.0536</td> <td>    0.035</td> <td>   -1.548</td> <td> 0.122</td> <td>   -0.122</td> <td>    0.014</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x11</th>   <td>  755.9173</td> <td> 3543.200</td> <td>    0.213</td> <td> 0.831</td> <td>-6189.016</td> <td> 7700.851</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x12</th>   <td> 2.652e+04</td> <td> 2332.789</td> <td>   11.367</td> <td> 0.000</td> <td> 2.19e+04</td> <td> 3.11e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x13</th>   <td> 1.027e+05</td> <td> 2053.831</td> <td>   49.988</td> <td> 0.000</td> <td> 9.86e+04</td> <td> 1.07e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x14</th>   <td>  189.6764</td> <td>    3.355</td> <td>   56.530</td> <td> 0.000</td> <td>  183.100</td> <td>  196.253</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x15</th>   <td>  151.5704</td> <td>    4.301</td> <td>   35.242</td> <td> 0.000</td> <td>  143.140</td> <td>  160.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x16</th>   <td> 2528.0148</td> <td>   71.912</td> <td>   35.154</td> <td> 0.000</td> <td> 2387.062</td> <td> 2668.968</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x17</th>   <td>-1.231e+05</td> <td> 4.35e+04</td> <td>   -2.827</td> <td> 0.005</td> <td>-2.08e+05</td> <td>-3.78e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x18</th>   <td> 2.706e+05</td> <td> 1.67e+04</td> <td>   16.178</td> <td> 0.000</td> <td> 2.38e+05</td> <td> 3.03e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x19</th>   <td> 3.706e+04</td> <td> 1.41e+04</td> <td>    2.622</td> <td> 0.009</td> <td> 9358.938</td> <td> 6.48e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x20</th>   <td>-1.019e+05</td> <td> 1.16e+04</td> <td>   -8.818</td> <td> 0.000</td> <td>-1.25e+05</td> <td>-7.93e+04</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>17820.622</td> <th>  Durbin-Watson:     </th>  <td>   1.993</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>  <td> 0.000</td>   <th>  Jarque-Bera (JB):  </th> <td>1649691.884</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>           <td> 3.415</td>   <th>  Prob(JB):          </th>  <td>    0.00</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>       <td>45.252</td>   <th>  Cond. No.          </th>  <td>2.12e+18</td>  \n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.702\n",
       "Model:                            OLS   Adj. R-squared:                  0.702\n",
       "Method:                 Least Squares   F-statistic:                     2680.\n",
       "Date:                Wed, 11 Oct 2017   Prob (F-statistic):               0.00\n",
       "Time:                        21:57:52   Log-Likelihood:            -2.9453e+05\n",
       "No. Observations:               21613   AIC:                         5.891e+05\n",
       "Df Residuals:                   21593   BIC:                         5.893e+05\n",
       "Df Model:                          19                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const      -3.705e+06   1.23e+06     -3.002      0.003   -6.12e+06   -1.29e+06\n",
       "x1         -3.705e+06   1.23e+06     -3.002      0.003   -6.12e+06   -1.29e+06\n",
       "x2          1.096e+05   1.12e+04      9.763      0.000    8.76e+04    1.32e+05\n",
       "x3          6.868e+04   6809.365     10.086      0.000    5.53e+04     8.2e+04\n",
       "x4          1.388e+05   9342.321     14.856      0.000     1.2e+05    1.57e+05\n",
       "x5          2.963e+05   1.44e+04     20.639      0.000    2.68e+05    3.24e+05\n",
       "x6           5.06e+05   1.96e+04     25.760      0.000    4.67e+05    5.44e+05\n",
       "x7          3.122e+04   7264.811      4.297      0.000     1.7e+04    4.55e+04\n",
       "x8           -1.8e+06   6.72e+05     -2.677      0.007   -3.12e+06   -4.82e+05\n",
       "x9         -1.283e+07   7.96e+05    -16.124      0.000   -1.44e+07   -1.13e+07\n",
       "x10           -0.0536      0.035     -1.548      0.122      -0.122       0.014\n",
       "x11          755.9173   3543.200      0.213      0.831   -6189.016    7700.851\n",
       "x12         2.652e+04   2332.789     11.367      0.000    2.19e+04    3.11e+04\n",
       "x13         1.027e+05   2053.831     49.988      0.000    9.86e+04    1.07e+05\n",
       "x14          189.6764      3.355     56.530      0.000     183.100     196.253\n",
       "x15          151.5704      4.301     35.242      0.000     143.140     160.000\n",
       "x16         2528.0148     71.912     35.154      0.000    2387.062    2668.968\n",
       "x17        -1.231e+05   4.35e+04     -2.827      0.005   -2.08e+05   -3.78e+04\n",
       "x18         2.706e+05   1.67e+04     16.178      0.000    2.38e+05    3.03e+05\n",
       "x19         3.706e+04   1.41e+04      2.622      0.009    9358.938    6.48e+04\n",
       "x20        -1.019e+05   1.16e+04     -8.818      0.000   -1.25e+05   -7.93e+04\n",
       "==============================================================================\n",
       "Omnibus:                    17820.622   Durbin-Watson:                   1.993\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):          1649691.884\n",
       "Skew:                           3.415   Prob(JB):                         0.00\n",
       "Kurtosis:                      45.252   Cond. No.                     2.12e+18\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The smallest eigenvalue is 9.39e-24. This might indicate that there are\n",
       "strong multicollinearity problems or that the design matrix is singular.\n",
       "\"\"\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Building the optimal model using Backward Elimination - Removing Variable X10\n",
    "import statsmodels.formula.api as sm\n",
    "x=np.append(arr=np.ones((21613,1)).astype(int), values =x, axis=1)\n",
    "x_opt =x[:,[0,1,2,3,4,5,6,7,8,9,11,12,13,14,15,16,17,18,19,20,21]]\n",
    "regressor_OLS =sm.OLS(endog =y, exog=x_opt).fit()\n",
    "regressor_OLS.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th>  <td>   0.698</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th>  <td>   0.697</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>  <td>   2930.</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Wed, 11 Oct 2017</td> <th>  Prob (F-statistic):</th>   <td>  0.00</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>21:59:31</td>     <th>  Log-Likelihood:    </th> <td>-2.9470e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td> 21613</td>      <th>  AIC:               </th>  <td>5.894e+05</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td> 21595</td>      <th>  BIC:               </th>  <td>5.896e+05</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    17</td>      <th>                     </th>      <td> </td>     \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>      <td> </td>     \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>-1.232e+06</td> <td> 6.75e+05</td> <td>   -1.827</td> <td> 0.068</td> <td>-2.55e+06</td> <td> 8.97e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>-1.232e+06</td> <td> 6.75e+05</td> <td>   -1.827</td> <td> 0.068</td> <td>-2.55e+06</td> <td> 8.97e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>-1.232e+06</td> <td> 6.75e+05</td> <td>   -1.827</td> <td> 0.068</td> <td>-2.55e+06</td> <td> 8.97e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td> 1.162e+05</td> <td> 1.13e+04</td> <td>   10.283</td> <td> 0.000</td> <td>  9.4e+04</td> <td> 1.38e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th>    <td> 7.123e+04</td> <td> 6858.479</td> <td>   10.386</td> <td> 0.000</td> <td> 5.78e+04</td> <td> 8.47e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5</th>    <td> 1.396e+05</td> <td> 9405.926</td> <td>   14.843</td> <td> 0.000</td> <td> 1.21e+05</td> <td> 1.58e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x6</th>    <td> 3.067e+05</td> <td> 1.45e+04</td> <td>   21.213</td> <td> 0.000</td> <td> 2.78e+05</td> <td> 3.35e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x7</th>    <td> 5.036e+05</td> <td> 1.98e+04</td> <td>   25.449</td> <td> 0.000</td> <td> 4.65e+05</td> <td> 5.42e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x8</th>    <td> 3.271e+04</td> <td> 7308.398</td> <td>    4.476</td> <td> 0.000</td> <td> 1.84e+04</td> <td>  4.7e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x9</th>    <td>-7.131e+06</td> <td> 5.84e+05</td> <td>  -12.202</td> <td> 0.000</td> <td>-8.28e+06</td> <td>-5.99e+06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x10</th>   <td>   -0.1139</td> <td>    0.034</td> <td>   -3.316</td> <td> 0.001</td> <td>   -0.181</td> <td>   -0.047</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x11</th>   <td> 6147.8924</td> <td> 3516.568</td> <td>    1.748</td> <td> 0.080</td> <td> -744.841</td> <td>  1.3e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x12</th>   <td> 2.809e+04</td> <td> 2341.680</td> <td>   11.997</td> <td> 0.000</td> <td> 2.35e+04</td> <td> 3.27e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x13</th>   <td> 1.047e+05</td> <td> 2058.787</td> <td>   50.838</td> <td> 0.000</td> <td> 1.01e+05</td> <td> 1.09e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x14</th>   <td>  182.9504</td> <td>    3.291</td> <td>   55.591</td> <td> 0.000</td> <td>  176.500</td> <td>  189.401</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x15</th>   <td>  154.7364</td> <td>    4.325</td> <td>   35.774</td> <td> 0.000</td> <td>  146.258</td> <td>  163.214</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x16</th>   <td> 2706.5364</td> <td>   68.289</td> <td>   39.634</td> <td> 0.000</td> <td> 2572.686</td> <td> 2840.387</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x17</th>   <td> 6.023e+04</td> <td> 4.25e+04</td> <td>    1.416</td> <td> 0.157</td> <td>-2.32e+04</td> <td> 1.44e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x18</th>   <td>  914.8300</td> <td>   68.752</td> <td>   13.306</td> <td> 0.000</td> <td>  780.072</td> <td> 1049.588</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x19</th>   <td> 1.491e+05</td> <td> 1.23e+04</td> <td>   12.139</td> <td> 0.000</td> <td> 1.25e+05</td> <td> 1.73e+05</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>18274.881</td> <th>  Durbin-Watson:     </th>  <td>   1.990</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>  <td> 0.000</td>   <th>  Jarque-Bera (JB):  </th> <td>1793604.668</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>           <td> 3.542</td>   <th>  Prob(JB):          </th>  <td>    0.00</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>       <td>47.062</td>   <th>  Cond. No.          </th>  <td>1.10e+19</td>  \n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.698\n",
       "Model:                            OLS   Adj. R-squared:                  0.697\n",
       "Method:                 Least Squares   F-statistic:                     2930.\n",
       "Date:                Wed, 11 Oct 2017   Prob (F-statistic):               0.00\n",
       "Time:                        21:59:31   Log-Likelihood:            -2.9470e+05\n",
       "No. Observations:               21613   AIC:                         5.894e+05\n",
       "Df Residuals:                   21595   BIC:                         5.896e+05\n",
       "Df Model:                          17                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const      -1.232e+06   6.75e+05     -1.827      0.068   -2.55e+06    8.97e+04\n",
       "x1         -1.232e+06   6.75e+05     -1.827      0.068   -2.55e+06    8.97e+04\n",
       "x2         -1.232e+06   6.75e+05     -1.827      0.068   -2.55e+06    8.97e+04\n",
       "x3          1.162e+05   1.13e+04     10.283      0.000     9.4e+04    1.38e+05\n",
       "x4          7.123e+04   6858.479     10.386      0.000    5.78e+04    8.47e+04\n",
       "x5          1.396e+05   9405.926     14.843      0.000    1.21e+05    1.58e+05\n",
       "x6          3.067e+05   1.45e+04     21.213      0.000    2.78e+05    3.35e+05\n",
       "x7          5.036e+05   1.98e+04     25.449      0.000    4.65e+05    5.42e+05\n",
       "x8          3.271e+04   7308.398      4.476      0.000    1.84e+04     4.7e+04\n",
       "x9         -7.131e+06   5.84e+05    -12.202      0.000   -8.28e+06   -5.99e+06\n",
       "x10           -0.1139      0.034     -3.316      0.001      -0.181      -0.047\n",
       "x11         6147.8924   3516.568      1.748      0.080    -744.841     1.3e+04\n",
       "x12         2.809e+04   2341.680     11.997      0.000    2.35e+04    3.27e+04\n",
       "x13         1.047e+05   2058.787     50.838      0.000    1.01e+05    1.09e+05\n",
       "x14          182.9504      3.291     55.591      0.000     176.500     189.401\n",
       "x15          154.7364      4.325     35.774      0.000     146.258     163.214\n",
       "x16         2706.5364     68.289     39.634      0.000    2572.686    2840.387\n",
       "x17         6.023e+04   4.25e+04      1.416      0.157   -2.32e+04    1.44e+05\n",
       "x18          914.8300     68.752     13.306      0.000     780.072    1049.588\n",
       "x19         1.491e+05   1.23e+04     12.139      0.000    1.25e+05    1.73e+05\n",
       "==============================================================================\n",
       "Omnibus:                    18274.881   Durbin-Watson:                   1.990\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):          1793604.668\n",
       "Skew:                           3.542   Prob(JB):                         0.00\n",
       "Kurtosis:                      47.062   Cond. No.                     1.10e+19\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The smallest eigenvalue is 3.5e-25. This might indicate that there are\n",
       "strong multicollinearity problems or that the design matrix is singular.\n",
       "\"\"\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Building the optimal model using Backward Elimination - Removing Variable X11\n",
    "import statsmodels.formula.api as sm\n",
    "x=np.append(arr=np.ones((21613,1)).astype(int), values =x, axis=1)\n",
    "x_opt =x[:,[0,1,2,3,4,5,6,7,8,9,12,13,14,15,16,17,18,19,20,21]]\n",
    "regressor_OLS =sm.OLS(endog =y, exog=x_opt).fit()\n",
    "regressor_OLS.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th>  <td>   0.691</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th>  <td>   0.690</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>  <td>   3213.</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Wed, 11 Oct 2017</td> <th>  Prob (F-statistic):</th>   <td>  0.00</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>22:00:20</td>     <th>  Log-Likelihood:    </th> <td>-2.9494e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td> 21613</td>      <th>  AIC:               </th>  <td>5.899e+05</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td> 21597</td>      <th>  BIC:               </th>  <td>5.900e+05</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    15</td>      <th>                     </th>      <td> </td>     \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>      <td> </td>     \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>-7.027e+06</td> <td> 1.26e+05</td> <td>  -55.968</td> <td> 0.000</td> <td>-7.27e+06</td> <td>-6.78e+06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>-7.027e+06</td> <td> 1.26e+05</td> <td>  -55.968</td> <td> 0.000</td> <td>-7.27e+06</td> <td>-6.78e+06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>-7.027e+06</td> <td> 1.26e+05</td> <td>  -55.968</td> <td> 0.000</td> <td>-7.27e+06</td> <td>-6.78e+06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td>-7.027e+06</td> <td> 1.26e+05</td> <td>  -55.968</td> <td> 0.000</td> <td>-7.27e+06</td> <td>-6.78e+06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th>    <td> 1.241e+05</td> <td> 1.14e+04</td> <td>   10.866</td> <td> 0.000</td> <td> 1.02e+05</td> <td> 1.46e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5</th>    <td> 7.678e+04</td> <td> 6927.154</td> <td>   11.084</td> <td> 0.000</td> <td> 6.32e+04</td> <td> 9.04e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x6</th>    <td> 1.495e+05</td> <td> 9498.188</td> <td>   15.744</td> <td> 0.000</td> <td> 1.31e+05</td> <td> 1.68e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x7</th>    <td> 3.203e+05</td> <td> 1.46e+04</td> <td>   21.929</td> <td> 0.000</td> <td> 2.92e+05</td> <td> 3.49e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x8</th>    <td> 5.247e+05</td> <td>    2e+04</td> <td>   26.247</td> <td> 0.000</td> <td> 4.85e+05</td> <td> 5.64e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x9</th>    <td> 3.845e+04</td> <td> 7387.381</td> <td>    5.205</td> <td> 0.000</td> <td>  2.4e+04</td> <td> 5.29e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x10</th>   <td>  162.5054</td> <td>    3.114</td> <td>   52.188</td> <td> 0.000</td> <td>  156.402</td> <td>  168.609</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x11</th>   <td>   -0.0548</td> <td>    0.035</td> <td>   -1.584</td> <td> 0.113</td> <td>   -0.123</td> <td>    0.013</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x12</th>   <td> 6143.1275</td> <td> 3550.694</td> <td>    1.730</td> <td> 0.084</td> <td> -816.495</td> <td> 1.31e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x13</th>   <td> 2.712e+04</td> <td> 2366.081</td> <td>   11.461</td> <td> 0.000</td> <td> 2.25e+04</td> <td> 3.18e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x14</th>   <td> 1.094e+05</td> <td> 2060.516</td> <td>   53.108</td> <td> 0.000</td> <td> 1.05e+05</td> <td> 1.13e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x15</th>   <td>  -29.7229</td> <td>    4.249</td> <td>   -6.995</td> <td> 0.000</td> <td>  -38.052</td> <td>  -21.394</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x16</th>   <td> 2640.6069</td> <td>   68.889</td> <td>   38.331</td> <td> 0.000</td> <td> 2505.580</td> <td> 2775.634</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x17</th>   <td> 5.715e+05</td> <td> 1.06e+04</td> <td>   53.805</td> <td> 0.000</td> <td> 5.51e+05</td> <td> 5.92e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x18</th>   <td>  673.0264</td> <td>   68.005</td> <td>    9.897</td> <td> 0.000</td> <td>  539.732</td> <td>  806.321</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>18850.990</td> <th>  Durbin-Watson:     </th>  <td>   1.987</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>  <td> 0.000</td>   <th>  Jarque-Bera (JB):  </th> <td>2013930.270</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>           <td> 3.704</td>   <th>  Prob(JB):          </th>  <td>    0.00</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>       <td>49.706</td>   <th>  Cond. No.          </th>  <td>8.67e+18</td>  \n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.691\n",
       "Model:                            OLS   Adj. R-squared:                  0.690\n",
       "Method:                 Least Squares   F-statistic:                     3213.\n",
       "Date:                Wed, 11 Oct 2017   Prob (F-statistic):               0.00\n",
       "Time:                        22:00:20   Log-Likelihood:            -2.9494e+05\n",
       "No. Observations:               21613   AIC:                         5.899e+05\n",
       "Df Residuals:                   21597   BIC:                         5.900e+05\n",
       "Df Model:                          15                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const      -7.027e+06   1.26e+05    -55.968      0.000   -7.27e+06   -6.78e+06\n",
       "x1         -7.027e+06   1.26e+05    -55.968      0.000   -7.27e+06   -6.78e+06\n",
       "x2         -7.027e+06   1.26e+05    -55.968      0.000   -7.27e+06   -6.78e+06\n",
       "x3         -7.027e+06   1.26e+05    -55.968      0.000   -7.27e+06   -6.78e+06\n",
       "x4          1.241e+05   1.14e+04     10.866      0.000    1.02e+05    1.46e+05\n",
       "x5          7.678e+04   6927.154     11.084      0.000    6.32e+04    9.04e+04\n",
       "x6          1.495e+05   9498.188     15.744      0.000    1.31e+05    1.68e+05\n",
       "x7          3.203e+05   1.46e+04     21.929      0.000    2.92e+05    3.49e+05\n",
       "x8          5.247e+05      2e+04     26.247      0.000    4.85e+05    5.64e+05\n",
       "x9          3.845e+04   7387.381      5.205      0.000     2.4e+04    5.29e+04\n",
       "x10          162.5054      3.114     52.188      0.000     156.402     168.609\n",
       "x11           -0.0548      0.035     -1.584      0.113      -0.123       0.013\n",
       "x12         6143.1275   3550.694      1.730      0.084    -816.495    1.31e+04\n",
       "x13         2.712e+04   2366.081     11.461      0.000    2.25e+04    3.18e+04\n",
       "x14         1.094e+05   2060.516     53.108      0.000    1.05e+05    1.13e+05\n",
       "x15          -29.7229      4.249     -6.995      0.000     -38.052     -21.394\n",
       "x16         2640.6069     68.889     38.331      0.000    2505.580    2775.634\n",
       "x17         5.715e+05   1.06e+04     53.805      0.000    5.51e+05    5.92e+05\n",
       "x18          673.0264     68.005      9.897      0.000     539.732     806.321\n",
       "==============================================================================\n",
       "Omnibus:                    18850.990   Durbin-Watson:                   1.987\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):          2013930.270\n",
       "Skew:                           3.704   Prob(JB):                         0.00\n",
       "Kurtosis:                      49.706   Cond. No.                     8.67e+18\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The smallest eigenvalue is 5.59e-25. This might indicate that there are\n",
       "strong multicollinearity problems or that the design matrix is singular.\n",
       "\"\"\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Building the optimal model using Backward Elimination - Removing Variable X17\n",
    "import statsmodels.formula.api as sm\n",
    "x=np.append(arr=np.ones((21613,1)).astype(int), values =x, axis=1)\n",
    "x_opt =x[:,[0,1,2,3,4,5,6,7,8,9,12,13,14,15,16,18,19,20,21]]\n",
    "regressor_OLS =sm.OLS(endog =y, exog=x_opt).fit()\n",
    "regressor_OLS.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th>  <td>   0.639</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th>  <td>   0.639</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>  <td>   3476.</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Wed, 11 Oct 2017</td> <th>  Prob (F-statistic):</th>   <td>  0.00</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>22:10:14</td>     <th>  Log-Likelihood:    </th> <td>-2.9661e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td> 21613</td>      <th>  AIC:               </th>  <td>5.932e+05</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td> 21601</td>      <th>  BIC:               </th>  <td>5.933e+05</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    11</td>      <th>                     </th>      <td> </td>     \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>      <td> </td>     \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>-1.744e+05</td> <td> 2476.554</td> <td>  -70.429</td> <td> 0.000</td> <td>-1.79e+05</td> <td> -1.7e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>-1.744e+05</td> <td> 2476.554</td> <td>  -70.429</td> <td> 0.000</td> <td>-1.79e+05</td> <td> -1.7e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>-1.744e+05</td> <td> 2476.554</td> <td>  -70.429</td> <td> 0.000</td> <td>-1.79e+05</td> <td> -1.7e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td>-1.744e+05</td> <td> 2476.554</td> <td>  -70.429</td> <td> 0.000</td> <td>-1.79e+05</td> <td> -1.7e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th>    <td>-1.744e+05</td> <td> 2476.554</td> <td>  -70.429</td> <td> 0.000</td> <td>-1.79e+05</td> <td> -1.7e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5</th>    <td>-1.744e+05</td> <td> 2476.554</td> <td>  -70.429</td> <td> 0.000</td> <td>-1.79e+05</td> <td> -1.7e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x6</th>    <td> 1.206e+05</td> <td> 1.23e+04</td> <td>    9.782</td> <td> 0.000</td> <td> 9.64e+04</td> <td> 1.45e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x7</th>    <td> 6.471e+04</td> <td> 7470.066</td> <td>    8.663</td> <td> 0.000</td> <td> 5.01e+04</td> <td> 7.94e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x8</th>    <td> 1.393e+05</td> <td> 1.02e+04</td> <td>   13.655</td> <td> 0.000</td> <td> 1.19e+05</td> <td> 1.59e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x9</th>    <td> 5.249e+05</td> <td> 1.28e+04</td> <td>   40.962</td> <td> 0.000</td> <td>    5e+05</td> <td>  5.5e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x10</th>   <td> 3.565e+04</td> <td> 3458.756</td> <td>   10.307</td> <td> 0.000</td> <td> 2.89e+04</td> <td> 4.24e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x11</th>   <td>   98.0702</td> <td>    2.177</td> <td>   45.038</td> <td> 0.000</td> <td>   93.802</td> <td>  102.338</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x12</th>   <td>   -0.1792</td> <td>    0.037</td> <td>   -4.806</td> <td> 0.000</td> <td>   -0.252</td> <td>   -0.106</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x13</th>   <td> 2.703e+04</td> <td> 3788.124</td> <td>    7.135</td> <td> 0.000</td> <td> 1.96e+04</td> <td> 3.45e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x14</th>   <td> 1.294e+05</td> <td> 2183.861</td> <td>   59.231</td> <td> 0.000</td> <td> 1.25e+05</td> <td> 1.34e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x15</th>   <td>   49.2902</td> <td>    2.190</td> <td>   22.511</td> <td> 0.000</td> <td>   44.998</td> <td>   53.582</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x16</th>   <td>   48.7800</td> <td>    2.806</td> <td>   17.384</td> <td> 0.000</td> <td>   43.280</td> <td>   54.280</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x17</th>   <td> 3718.5448</td> <td>   65.956</td> <td>   56.379</td> <td> 0.000</td> <td> 3589.267</td> <td> 3847.823</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>16918.427</td> <th>  Durbin-Watson:     </th>  <td>   1.975</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>  <td> 0.000</td>   <th>  Jarque-Bera (JB):  </th> <td>1350714.013</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>           <td> 3.180</td>   <th>  Prob(JB):          </th>  <td>    0.00</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>       <td>41.202</td>   <th>  Cond. No.          </th>  <td>2.24e+21</td>  \n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.639\n",
       "Model:                            OLS   Adj. R-squared:                  0.639\n",
       "Method:                 Least Squares   F-statistic:                     3476.\n",
       "Date:                Wed, 11 Oct 2017   Prob (F-statistic):               0.00\n",
       "Time:                        22:10:14   Log-Likelihood:            -2.9661e+05\n",
       "No. Observations:               21613   AIC:                         5.932e+05\n",
       "Df Residuals:                   21601   BIC:                         5.933e+05\n",
       "Df Model:                          11                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const      -1.744e+05   2476.554    -70.429      0.000   -1.79e+05    -1.7e+05\n",
       "x1         -1.744e+05   2476.554    -70.429      0.000   -1.79e+05    -1.7e+05\n",
       "x2         -1.744e+05   2476.554    -70.429      0.000   -1.79e+05    -1.7e+05\n",
       "x3         -1.744e+05   2476.554    -70.429      0.000   -1.79e+05    -1.7e+05\n",
       "x4         -1.744e+05   2476.554    -70.429      0.000   -1.79e+05    -1.7e+05\n",
       "x5         -1.744e+05   2476.554    -70.429      0.000   -1.79e+05    -1.7e+05\n",
       "x6          1.206e+05   1.23e+04      9.782      0.000    9.64e+04    1.45e+05\n",
       "x7          6.471e+04   7470.066      8.663      0.000    5.01e+04    7.94e+04\n",
       "x8          1.393e+05   1.02e+04     13.655      0.000    1.19e+05    1.59e+05\n",
       "x9          5.249e+05   1.28e+04     40.962      0.000       5e+05     5.5e+05\n",
       "x10         3.565e+04   3458.756     10.307      0.000    2.89e+04    4.24e+04\n",
       "x11           98.0702      2.177     45.038      0.000      93.802     102.338\n",
       "x12           -0.1792      0.037     -4.806      0.000      -0.252      -0.106\n",
       "x13         2.703e+04   3788.124      7.135      0.000    1.96e+04    3.45e+04\n",
       "x14         1.294e+05   2183.861     59.231      0.000    1.25e+05    1.34e+05\n",
       "x15           49.2902      2.190     22.511      0.000      44.998      53.582\n",
       "x16           48.7800      2.806     17.384      0.000      43.280      54.280\n",
       "x17         3718.5448     65.956     56.379      0.000    3589.267    3847.823\n",
       "==============================================================================\n",
       "Omnibus:                    16918.427   Durbin-Watson:                   1.975\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):          1350714.013\n",
       "Skew:                           3.180   Prob(JB):                         0.00\n",
       "Kurtosis:                      41.202   Cond. No.                     2.24e+21\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The smallest eigenvalue is 8.4e-30. This might indicate that there are\n",
       "strong multicollinearity problems or that the design matrix is singular.\n",
       "\"\"\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Building the optimal model using Backward Elimination - Removing Variable X12\n",
    "import statsmodels.formula.api as sm\n",
    "x=np.append(arr=np.ones((21613,1)).astype(int), values =x, axis=1)\n",
    "x_opt =x[:,[0,1,2,3,4,5,6,7,8,9,13,14,15,16,18,19,20,21]]\n",
    "regressor_OLS =sm.OLS(endog =y, exog=x_opt).fit()\n",
    "regressor_OLS.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1.00000000e+00,   1.00000000e+00,   1.00000000e+00,\n",
       "         1.00000000e+00,   1.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   3.56000000e+03,   9.79600000e+03,\n",
       "         1.00000000e+00,   3.00000000e+00,   1.86000000e+03,\n",
       "         1.70000000e+03,   5.00000000e+01,   4.76007000e+01])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_opt[10,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Splitting the dataset into the Training set and Test set\n",
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_opt, y, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "210023.81028543544"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting Multiple Linear Regression to the Training set\n",
    "from sklearn.linear_model import LinearRegression\n",
    "regressor = LinearRegression()\n",
    "regressor.fit(X_train, y_train)\n",
    "\n",
    "# Predicting the Test set results\n",
    "y_pred = regressor.predict(X_test)\n",
    "\n",
    "# Evaluating Model Performance\n",
    "from sklearn.metrics import mean_squared_error\n",
    "lin_mse_LR = mean_squared_error(y_test, y_pred)\n",
    "lin_rmse_LR = np.sqrt(lin_mse_LR)\n",
    "lin_rmse_LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "252662.54617062683"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Decision Tree Modeling\n",
    "\n",
    "# Fitting Decision Tree Regression Model to the Training set\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "tree_reg = DecisionTreeRegressor()\n",
    "tree_reg.fit(X_train, y_train)\n",
    "\n",
    "# Predicting the Test set results\n",
    "y_pred = tree_reg.predict(X_test)\n",
    "\n",
    "# Evaluating Model Decision Tree Performance\n",
    "from sklearn.metrics import mean_squared_error\n",
    "lin_mse_DT = mean_squared_error(y_test, y_pred)\n",
    "lin_rmse_DT = np.sqrt(lin_mse_DT)\n",
    "lin_rmse_DT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "196624.92351455597"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  Random Forest Model\n",
    "\n",
    "# Fitting a Random Forest  Model to the Training set\n",
    "from sklearn.ensemble import RandomForestRegressor \n",
    "forest_reg = RandomForestRegressor()\n",
    "forest_reg.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "\n",
    "# Predicting the Test set results\n",
    "y_pred = forest_reg.predict(X_test)\n",
    "\n",
    "# Evaluating Model Random Forest Performance\n",
    "from sklearn.metrics import mean_squared_error\n",
    "lin_mse_RF = mean_squared_error(y_test, y_pred)\n",
    "lin_rmse_RF = np.sqrt(lin_mse_RF)\n",
    "lin_rmse_RF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
